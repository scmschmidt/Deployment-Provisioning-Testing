#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Deploys a cloud infrastructure by using terraform and the project
https://github.com/scmschmidt/simple_deployment.

This script gets called by `dpt` and relies on the following:

- It gets called with either 'deploy' or 'destroy' as the 
  first (and only) parameter.

- The current directory contains a YAML file 'config', containing
  the infrastructure description.

- The "real" provider can be found in config['provider_args'].

- The current directory can freely used. Only the files 'provider'
  (this script), the configuration 'config', 'output' and 'result.yaml'
  are reserved.

- The exit code (0/1) defines, if this script was successful or not.

- Messages shall be written in a neat format (e.g. with timestamps) 
  to stdout (including errors)
  The `dtp` program will capture it and write the file 'output'

- The provider must create a YAML file called 'result,yaml' in the current
  directory, which contains the IP addresses of the deployed machines.
  The `dtp` program will process the data further.


Exitcodes:

    0   Everything went fine.
    1   Something went wrong

Ideas:
    - 
    - 

ToDo:
    - 


Changelog:
----------
01.08.2022      v0.1        - and so it begins...
15.08.2022      v0.2        - Works so far and just needs minor adjustment.
"""

import copy
import datetime
import hashlib
from ipaddress import ip_address
import jinja2
import json
import os
import schema
import subprocess
import sys
import time
import random
import yaml

import pprint


VERSION = 'v0.1'
AUTHOR = 'soeren.schmidt@suse.com'


def log(text: str, level: str='info' ) -> None:
    """
    Prints the text to stdout preceded by timestamp and category. 
    """
    category = {'info': 'INFO',
                'success': ' OK ',
                'fail': 'FAIL',
                'warn': 'WARN' 
               }[level]
    print(f'[{datetime.datetime.now()}] [{category}] {text}', file=sys.stdout)

def bye(rc: int=0) -> None:
    """
    Logs termination message and exits with given exit code.
    """
    if rc == 0:
        log(f'Terminating successfully (exit code {rc}).', 'success')
    else:
        log(f'Terminating with failure (exit code {rc})!', 'fail')
    sys.exit(rc)

def load_and_validate(config_file: str) -> dict:
    """
    Loads the config file (YAML) into a dictionary and validates it
    against a schema afterwards.

    Terminates with error message and exit code 1 on failure.
    """

    # Load config
    try: 
        with open(config_file) as f:
            content = yaml.safe_load(f)
    except Exception as err:
        log(f'Error reading landscape: {err}', 'fail')
        bye(1)
    log(f'Landscape "{config_file}" loaded successfully.')

    # Check for an empty config.
    if not content:
        log(f'The landscape "{config_file}" is empty!', 'fail')
        bye(1)

    # Validate against schema.
    config_schema = schema.Schema({
        'build_dir': str,
        'provider_dir': str,
        'config': {

            schema.Optional('skip_deploy'): bool,                                 

            # Azure requirement: may not contain the special characters: `\/"[]:|<>+=;,?*@&~!#$%^()_{}
            'name': schema.Regex('^[a-z.][a-z0-9.-]{1,40}$',
                                 error='"name" must be a string matching "^[a-z.][a-z0-9.-]{1,40}$".'),
            schema.Optional('update_provider'): bool,                                 
            schema.Optional('remote_user'): schema.Regex('^[a-z][-a-z0-9]*$',
                                                         error='"remote_user" must be a string matching "^[a-z][-a-z0-9]*$".'),
            'remote_user_public_key_file': str, 
            schema.Optional('enable_root_login'): bool,
            schema.Optional('keymap'): str,
            'location': str,
            'provider': str,
            schema.Optional('registration_server'): str,
            schema.Optional('subnet'): schema.Regex('^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}/[0-9]{1,2}$',
                                                    error='Must be a subnet declaration in the form: A.B.C.D/M'),
            schema.Optional('subscription_registration_key'): str,
            'hosts': [{
               'count': schema.And(int, 
                                    lambda n: True if isinstance(n, int) and n >= 1 else False,
                                    error='"count" must be an integer greater than 1'),
                schema.Optional('size'): str,
                schema.Optional('os'): str,
                schema.Optional('labels'): list
            }],
            'images': { str: { str: str } },
            'sizing': { str:  schema.Or({ str: str }, { str: { str: int } }) }
        }

    }, ignore_extra_keys=True)
    try:
        config_schema.validate(content)
    except schema.SchemaError as se:
        msgs = ['Errors during schema validation:'] 
        for err in se.errors + se.autos:
            if err:
                msgs.append(err)
        log('\n\t'.join(msgs), 'fail')
        bye(1)
    log('Schema validation passed.')

    return content

def make_plan(config: dict) -> dict:
    """
    Uses config and the templates to create 
    a the terraform plan for 'simple_deployment'.

    It returns the updated config.
    """

    template = f'''{config['provider_dir']}/templates/{config['provider_args']}-main.tf.template'''
    terraform_dir = 'terraform'
    terraform_file = f'{terraform_dir}/main.tf'

    # Generate machine description.
    # To avoid unnecessary machine destruction and creation if count changes,
    # each configuration gets an id (hash of the configuration), which is used
    # in the names of the machines. 
    machine_definition = {}
    try: 
        for block in config['config']['hosts']:

            # Create the hash of the machine configuration.
            machine_config = copy.deepcopy(block) 
            del(machine_config['count'])
            hash = hashlib.blake2s(yaml.dump(machine_config).encode('utf-8'), digest_size=8).hexdigest()

            # Create a new entry, if the config is new.
            if hash not in machine_definition:
                machine_definition[hash] = { 'current': 0, 'config': machine_config, 'names': [] }
                index = 1
            
            # Add hosts.
            for index in range(machine_definition[hash]['current'], machine_definition[hash]['current']+block['count']):
                machine_definition[hash]['names'].append(f'{hash}-{index}')
            machine_definition[hash]['current'] = index + 1
    except Exception as err:
        log(f'Generating machine description failed: {err}', 'fail')
        bye(1)

    # Now we prepare a machine dict to be used by the template.
    machines = []
    for _, data in machine_definition.items():
        for name in data['names']:
            machines.append({
                'name': f'''{config['config']['name']}-{name}''',
                'shortname': name,
                'size': data['config']['size'], 
                'os': data['config']['os'],
                'labels': data['config']['labels'] if 'labels' in data['config'] else None
            })
    config['config']['machines'] = machines

    # Read the content of 'remote_user_public_key_file' to put it into the template.
    try:
        with open(os.path.expanduser(config['config']['remote_user_public_key_file']), 'r') as f:
            config['config']['admin_user_key'] = ''.join(f.readlines()).strip()
    except Exception as err:
        log(f'Error reading public key for remote user: {err}', 'fail')
        bye(1)  

    # Fill in the template.
    try: 
        with open(template) as f:
            plan = jinja2.Template(f.read()).render(config['config'])
    except Exception as err:
        log(f'Error reading landscape: {err}', 'fail')
        bye(1)

    # Save plan.
    try:
        if not os.path.exists(terraform_dir):
            os.mkdir(terraform_dir, mode = 0o700)
        with open(terraform_file, 'w') as f:
            f.write(plan)
    except Exception as err:
        log(f'Error writing the plan file: {err}', 'fail')
        bye(1)

    return config

def write_map(config: dict, section: str, file: str) -> None:
    """
    Writes section of config into a file. 
    Either the 'default' subsection or the 'location` part is written
    into the file, depending if there is a location subsection.

    Also the image file for AWS has a slightly different structure which 
    has to taken into account.
    """

    try:
        location = config['config']['location']
        if location not in config['config'][section]:
            subsection = 'default'
            log(f'''Preparing "{file}": Section "{location}" not found in config, using "default".''')
        else:
            subsection = location
            log(f'''Preparing "{file}": Section "{location}" found in config.''')
            
        with open(file, 'w') as f:
            # For AWS we need to include the location!   !!!!!DEFAULT IS NOT SUPPORTED!!!!!!
            if section == 'images' and config['provider_args'] == 'aws':
                content = {location: config['config'][section][subsection]}
            else:
                content = config['config'][section][subsection]
            f.write(yaml.dump(content))
    except Exception as err:
        log(f'Error writing "{section}" to file: {err}', 'fail')
        bye(1)
    log(f'File "{file}" written.', 'success')

def terraform(command: list) -> None:
    """
    Executes the terraform command and logs stdout and stderr.
    The execution will be done in a subdirectory ``terraform``,
    which must exist and contain a ``main.tf`` file.

    The output will be logged continuously and also
    returned.  
    
    Terminates on failure.
    """ 

    terraform_dir = 'terraform'

    environment = os.environ.copy()
    environment['TF_IN_AUTOMATION'] = '1'
    
    command.insert(0, 'terraform')
    command_string = ' ' .join(command)

    output = []

    log(f'Run now "{command_string}"')
    try:
        with subprocess.Popen(command, 
                              stdout = subprocess.PIPE, 
                              stderr = subprocess.STDOUT,
                              encoding = 'utf-8',
                              cwd = terraform_dir,
                              env = environment
                             ) as proc:
            while proc.poll() is None:
                for line in proc.stdout.readlines():
                    log(f'{command_string}: {line.strip()}')  
                    output.append(line.strip())

            if proc.returncode != 0:
                raise ValueError(f'terraform exited with return code {proc.returncode}.')
                          
    except Exception as err:
        log(f'Execution of "{command_string}" failed: {err}', 'fail')
        bye(1) 

    return output     

def update_config(config: dict, terraform_output: str, filename: str) -> None:
    """
    Enriches the machines part of the config with the data from the
    terraform output. and writes it into a file.
    """

    try:
        # Read JSON output and create a lookup table
        lookup_table = {}
        for address_string in json.loads(terraform_output)['machines']['value']:
            name, ip = address_string.split()
            lookup_table[name] = ip        

        # Walk through the machines and add the ip address.
        lookup_failure = False
        for machine in config['config']['machines']: 
            if machine['name'] in lookup_table:
               machine['ip_address'] = lookup_table[machine['name']]
            else:
                log(f'IP address of "{name}" not found in terraform output!', 'error')
                lookup_failure = True 

        # Lookup failures lead to an error.
        if lookup_failure:
            log(f'Some hosts have no IP address! Terminating.', 'error')
            bye(1)
    except Exception as err: 
        log(f'Error updated config fith IP addresses of hosts: {err}', 'fail')
        bye(1)

    try:
        # Write the updated config.
        yaml.Dumper.ignore_aliases = lambda *args : True
        with open(filename, 'w') as f:
            f.write(yaml.dump(config))
    except Exception as err: 
        log(f'Error creating updated config file "{filename}": {err}', 'fail')
        bye(1)

    log(f'File "{filename}" written.', 'success')

def delete(filename: str) -> None:
    """
    Simply deletes a file.
    """
    if os.path.exists(filename):
        try: 
            os.remove(filename)
        except Exception as err: 
            log(f'Error removing file "{filename}": {err}', 'fail')
            bye(1)
        log(f'File "{filename}" deleted.', 'success')
    else:
        log(f'File "{filename}" does not exist. Nothing to delete.', 'success')


def main():

    # Print greeting.
    log(f'''Running: {' '.join(sys.argv)} (Pid: {os.getpid()})''')

    # Check action and translate it into the terraform command.
    
    if sys.argv[1] not in ['deploy', 'destroy']:
        log(f'Unknown action "{sys.argv[1]}"! Only "deploy" and "destroy" are supported.', 'fail')
        bye(1)
    action = 'apply' if sys.argv[1] == 'deploy' else sys.argv[1]

    # Delete any existing config generated for provisioners from previous runs.
    delete('config_provisioner')

    # Load and validate configuration file.
    config = load_and_validate('config_provider')

    # Terminate premature if skip is true.
    if 'skip_deploy' in config['config'] and config['config']['skip_deploy']:
        log('Parameter "skip_deploy" is set to true. Skip provisioning!', 'warn')
        bye(0)

    # Create terraform plan from templates.
    config = make_plan(config)

    # Generate/Save image and size files
    write_map(config, 'images', f'''terraform/images_{config['provider_args']}.yaml''')
    write_map(config, 'sizing', f'''terraform/sizing_{config['provider_args']}.yaml''')

    # Now we call terraform.
    # Recommendations for terraform options come from: 
    # https://learn.hashicorp.com/tutorials/terraform/automate-terraform?in=terraform/automation&utm_source=WEBSITE&utm_medium=WEB_IO&utm_offer=ARTICLE_PAGE&utm_content=DOCS
    
    # Executing `terraform init`.
    if 'update_provider' in  config['config'] and config['config']['update_provider']:
        terraform(['init', '-input=false', '-upgrade'])
    terraform(['init', '-input=false'])

    # Executing `terraform plan`.
    terraform(['plan', '-input=false'])

    # Depending on the command, we apply or destroy.
    terraform([action, '-input=false', '-auto-approve'])

    # In case of 'apply' we update the config.
    if action == 'apply':
        terraform_output = '\n'.join(terraform(['output', '-json']))
        update_config(config, terraform_output, config['provisioner_config'])

    # In case of 'delete' we delete the config.
    if action == 'destroy':
        delete('config_provider')

    # Say good bye.
    bye(0)


if __name__ == '__main__':
    main()

# host_key_checking = False